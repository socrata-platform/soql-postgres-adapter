# This should be basically the same for all secondaries

com.socrata.coordinator.secondary-watcher {
  instance = "{{ TRUTH_CLUSTER }}"

  # So we have good news and bad news.
  # The bad news is in the docker world we don't have the notion of an instance that will come back and 
  # reclaim its work based on its own uuid when it restarts, ever new container will have a new uuid.
  # The good news is that once we accept that containers will never come back with their own UUID
  # and will be killed quickly, having a shorter claim timeout is ok despite still having a bug where
  # we stop the claim manager update when we start shutting down, not when we finish, so if we have
  # an extended shutdown our claim can be stolen.
  watcher-id = "{{ UUID }}"
  claim-timeout = "30m"

  database {
    # Running out of pooled connections can result in strange and difficult to detect failure conditions.
    # For example, the claim manager can get blocked resulting in claims not being updated and thus stolen.
    # We control concurrency by the number of workers combined with the number of secondary instances configured, so
    # we set it to a "essentially unlimited" value for the secondary watcher.
    c3p0.maxPoolSize = 10000
    host = "{{ DATA_COORDINATOR_DB_HOST }}"
    port = "{{ DATA_COORDINATOR_DB_PORT }}"
    database = "{{ DATA_COORDINATOR_DB_NAME }}"
    username = "{{ DATA_COORDINATOR_DB_USER }}"
    {{ DATA_COORDINATOR_DB_PASSWORD_LINE }}
  }

  secondary {
    # unused
    defaultGroups = []
    groups = { }

    # The derived image will include the secondary configuration information necessary for the
    # specific secondary type.  We run a separate secondary watcher per secondary type for
    # isolation and to independently control scaling.
    include "{{ SERVER_ROOT }}/secondary.conf"
  }

  metrics {
    enable-graphite = {{ ENABLE_GRAPHITE }}
    graphite-host = "{{ GRAPHITE_HOST }}"
    graphite-port = "{{ GRAPHITE_PORT }}"
    log-metrics = {{ LOG_METRICS }}
  }

  producer {
    queues = "{{ PRODUCER_QUEUES }}"
    eurybates {
      producers = "{{ EURYBATES_PRODUCERS }}"
      activemq.connection-string = "{{ AMQ_URL }}"
    }
    zookeeper {
      conn-spec = "{{ ZOOKEEPER_ENSEMBLE }}"
      session-timeout = "{{ ZOOKEEPER_SESSION_TIMEOUT }}"
    }
  }
}
